from dotenv import load_dotenv
load_dotenv()

import streamlit as st
import os
import traceback
from utilities.llm_helper import LLMHelper
import regex as re

from utilities.logger import Logger

logger = Logger().get_logger()

# æ£€æŸ¥æ¨¡å‹éƒ¨ç½²
def check_deployment():
    # æ£€æŸ¥ LLM
    try:
        llm_helper = LLMHelper()
        llm_helper.get_completion("Generate a joke!")
        st.success(f"""LLM æ£€æµ‹æ­£å¸¸ï¼Œéƒ¨ç½²åç§°ä¸º {llm_helper.deployment_name}""")
    except Exception as e:
        st.error(
            f"""LLM æ£€æµ‹å¼‚å¸¸ï¼Œè¯·æ£€æŸ¥ "{llm_helper.deployment_name}" æ˜¯å¦å·²ç»éƒ¨ç½²åˆ° {llm_helper.api_base}""")
        st.error(traceback.format_exc())

    # æ£€æŸ¥ Embeddings
    try:
        llm_helper = LLMHelper()
        llm_helper.embeddings.embed_documents(texts=["æµ‹è¯•"])
        st.success(f"""Embedding Model æ£€æµ‹æ­£å¸¸ï¼Œéƒ¨ç½²åç§°ä¸º {llm_helper.model}""")
    except Exception as e:
        st.error(
            f"""Embedding Model æ£€æµ‹å¼‚å¸¸ï¼Œè¯·æ£€æŸ¥ "{llm_helper.model}" æ˜¯å¦å·²ç»éƒ¨ç½²åˆ° {llm_helper.api_base}ã€‚""")
        st.error(traceback.format_exc())

    # æ£€æŸ¥ Vectors
    try:
        llm_helper = LLMHelper()
        if llm_helper.vector_store_type == "Redis":
            if llm_helper.vector_store.check_existing_index("embeddings-index"):
                st.warning("""Vectors Database ç´¢å¼•å·²å­˜åœ¨ï¼Œæ‚¨å¯èƒ½ç”¨çš„æ˜¯ Redis å†å²æ•°æ®
                    """)
            else:
                st.success("Vectors Database æ£€æµ‹æ­£å¸¸ï¼Œä½¿ç”¨ Redis å‘é‡æ•°æ®åº“")
        else:
            if llm_helper.vector_store.check_existing_index("embeddings-index"):
                st.warning("""Vectors Database æ£€æµ‹å¼‚å¸¸ï¼Œè¯·æ£€æŸ¥ Milvus çš„é…ç½®æ˜¯å¦æ­£ç¡®
                    """)
            else:
                st.success("Vectors Database æ£€æµ‹æ­£å¸¸ï¼Œä½¿ç”¨ Milvus å‘é‡æ•°æ®åº“")
    except Exception as e:
        st.error(f"""Vectors Database æ£€æµ‹å¼‚å¸¸ï¼Œè¯·æ£€æŸ¥é…ç½®æ˜¯å¦æ­£ç¡®""")
        st.error(traceback.format_exc())

# æ£€æŸ¥æç¤ºè¯æ˜¯å¦åŒ…å«æŒ‡å®šçš„å˜é‡ï¼Œå¦åˆ™æŒ‰é»˜è®¤å†…å®¹è¿”å›
def check_variables_in_prompt():
    if "{summaries}" not in st.session_state.custom_prompt:
        st.warning("""ä½ çš„æç¤ºè¯ä¸åŒ…å«å˜é‡ "{summaries} å…³é”®å­—""")
        st.session_state.custom_prompt = ""
    if "{question}" not in st.session_state.custom_prompt:
        st.warning("""ä½ çš„æç¤ºè¯ä¸åŒ…å«å˜é‡ "{question} å…³é”®å­—""")
        st.session_state.custom_prompt = ""


# ä¿å­˜ç”¨æˆ·çš„æé—®å†…å®¹
def ask_followup_question(followup_question):
    st.session_state.asked_question = followup_question
    st.session_state["input_message_key"] = st.session_state["input_message_key"] + 1


# ä¿å­˜ç”¨æˆ·çš„æé—®å†…å®¹ï¼Œç”¨äºåç»­çš„è¯­ä¹‰æœç´¢
def question_asked():
    st.session_state.asked_question = st.session_state["input" + str(st.session_state["input_message_key"])]


try:

    # ä¼šè¯ç®¡ç†
    default_prompt = ""
    default_question = ""
    default_answer = ""
    if "question" not in st.session_state:
        st.session_state["question"] = default_question
    if "response" not in st.session_state:
        st.session_state["response"] = default_answer
    if "context" not in st.session_state:
        st.session_state["context"] = ""
    if "custom_prompt" not in st.session_state:
        st.session_state["custom_prompt"] = ""
    if "custom_temperature" not in st.session_state:
        st.session_state["custom_temperature"] = float(os.getenv("OPENAI_TEMPERATURE", 0.7))
    if 'sources' not in st.session_state:
        st.session_state['sources'] = ""
    if 'followup_questions' not in st.session_state:
        st.session_state['followup_questions'] = []
    if 'input_message_key' not in st.session_state:
        st.session_state ['input_message_key'] = 1
    if 'asked_question' not in st.session_state:
        st.session_state.asked_question = default_question

    # ä¾§æ èœå•
    menu_items = {
        "Get help": None,
        "Report a bug": None,
        "About": """
         ## Embeddings App
         Embedding testing application.
        """
    }
    st.set_page_config(
        page_title="æ™®ç›ŠAIçŸ¥è¯†åº“",
        page_icon = "ğŸ§Š",
        layout = "wide",
        initial_sidebar_state = "expanded",
        menu_items=menu_items)

    llm_helper = LLMHelper(custom_prompt=st.session_state.custom_prompt,
                           temperature=st.session_state.custom_temperature)

    # è‡ªå®šä¹‰æç¤ºè¯å˜é‡
    custom_prompt_placeholder = """{summaries}  
    Question: {question}  
    Answer:"""

    custom_prompt_help = """You can configure a custom prompt by adding the variables {summaries} and {question} to the prompt.  
    {summaries} will be replaced with the content of the documents retrieved from the VectorStore.  
    {question} will be replaced with the user's question.
    """

    # è®¾ç½®é¡µé¢å¸ƒå±€
    col1, col2, col3 = st.columns([1, 2, 1])
    with col1:
        st.image(os.path.join('images', 'logo.png'))

    st.write("<br>", unsafe_allow_html=True)

    col4, col5, col6 = st.columns([2, 2, 2])
    with col4:
        st.button("æ£€æŸ¥æ¨¡å‹éƒ¨ç½²", on_click=check_deployment)
    with col6:
        with st.expander("è®¾ç½®"):
            st.slider("Temperature", min_value=0.0, max_value=1.0, step=0.1, key='custom_temperature')
            st.text_area("Custom Prompt", key='custom_prompt', on_change=check_variables_in_prompt,
                         placeholder=custom_prompt_placeholder, help=custom_prompt_help, height=150)

    # æé—®è¾“å…¥æ¡†
    question = st.text_input("**è¯·åœ¨ä¸‹æ–¹è¾“å…¥ä½ çš„é—®é¢˜**", value=st.session_state['asked_question'],
                             key="input" + str(st.session_state['input_message_key']), on_change=question_asked)
    if st.session_state.asked_question != '':
        st.session_state['question'] = st.session_state.asked_question
        st.session_state.asked_question = ""
        st.session_state['question'], \
            st.session_state['response'], \
            st.session_state['context'], \
            st.session_state['sources'] = llm_helper.get_semantic_answer(st.session_state['question'], [])

        st.session_state['response'], followup_questions_list = llm_helper.extract_followup_questions(
            st.session_state['response'])

        st.session_state['followup_questions'] = followup_questions_list

    sourceList = []

    if st.session_state['sources'] or st.session_state['context']:
        st.session_state['response'], sourceList = llm_helper.get_links_filenames(
            st.session_state['response'], st.session_state['sources'])

    st.write("<br>", unsafe_allow_html=True)

    if st.session_state['response']:
        st.write("**å›ç­”** <br>", unsafe_allow_html=True)
        st.markdown(st.session_state['response'].split("\n")[0])

    st.write("<br>", unsafe_allow_html=True)

    if st.session_state['sources'] or st.session_state['context']:
        st.markdown('**ä¿¡æ¯æ¥æº**')
        for id in range(len(sourceList)):
            st.markdown(f"[{id + 1}] {sourceList[id]}")

        with st.expander("ç›¸å…³é—®é¢˜ä¸Šä¸‹æ–‡"):
            if not st.session_state['context'] is None and st.session_state['context'] != []:
                for content_source in st.session_state['context'].keys():
                    st.markdown(f"#### {content_source}")
                    for context_text in st.session_state['context'][content_source]:
                        st.markdown(f"{context_text}")

            st.markdown(f"æ¥æº: {st.session_state['sources']}")

    st.write("<br>", unsafe_allow_html=True)

    if len(st.session_state['followup_questions']) > 0:
        st.markdown('**æ‚¨è¿˜å¯ä»¥ç»§ç»­æé—®**')
    with st.container():
        for questionId, followup_question in enumerate(st.session_state['followup_questions']):
            if followup_question:
                str_followup_question = re.sub(r"(^|[^\\\\])'", r"\1\\'", followup_question)
                st.button(str_followup_question, key=1000 + questionId, on_click=ask_followup_question,
                          args=(followup_question,))

    for questionId, followup_question in enumerate(st.session_state['followup_questions']):
        if followup_question:
            str_followup_question = re.sub(r"(^|[^\\\\])'", r"\1\\'", followup_question)


except Exception:
    st.error(traceback.format_exc())
